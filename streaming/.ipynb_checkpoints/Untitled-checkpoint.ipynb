{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "baf5e564-25b0-4d17-8415-fa90de3b4c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from preprocessing import preprocessing\n",
    "\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "from tensorflow.keras.preprocessing import sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6a9bc87d-473a-43ce-847d-b41103ed4fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tknz_path = os.path.abspath('../model/tokenizer.pickle')\n",
    "with open(tknz_path,\"rb\") as f:\n",
    "    tokenizer = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9e436705-1d69-4469-bef8-45d4aa8d11ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = 'Chúng ta đã đi qua quãng thời gian đẹp nhất của nhau. Xa nhau là điều 2 đứa không hề muốn. Thôi thì coi như mình có duyên gặp nhau mà không đủ phận ở bên nhau. Em nợ anh 1 câu yêu thương cho mai này, xin hẹn nhau một kiếp sống khác ta sum vầy... Bài hát đúng tâm trạng. Cảm ơn nhé. ☘️ ☘️ ☘️. Chúng ta đã đi qua quãng thời gian đẹp nhất của nhau. Xa nhau là điều 2 đứa không hề muốn. Thôi thì coi như mình có duyên gặp nhau mà không đủ phận ở bên nhau. Em nợ anh 1 câu yêu thương cho mai này, xin hẹn nhau một kiếp sống khác ta sum vầy... Bài hát đúng tâm trạng. Cảm ơn nhé. ☘️ ☘️ ☘️'\n",
    "test = preprocessing(test)\n",
    "test = tokenizer.texts_to_sequences([test])\n",
    "test = sequence.pad_sequences(test,maxlen=80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c7921a1b-330d-454c-8ac2-8a2aaf5a793b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cho mai này xin hẹn nhau một kiếp sống khác ta sum_vầy bài hát đúng tâm_trạng cảm_ơn nhé ️ ️ ️ chúng_ta đã đi quá quãng thời_gian đẹp nhất của nhau xa nhau là điều đứa không hề muốn thôi_thì coi như mình có duyên gặp nhau mà không đủ phận ở bên nhau em nợ anh câu yêu_thương cho mai này xin hẹn nhau một kiếp sống khác ta sum_vầy bài hát đúng tâm_trạng cảm_ơn nhé ️ ️ ️']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.sequences_to_texts(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2d0cb318-68ac-4697-8ad2-e15a9d8aab3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = os.path.abspath('../model/Text_CNN_model_PhoW2V.h5')\n",
    "model = tf.keras.models.load_model(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bc07b170-f6ce-4e3d-8886-5fdf08eb737c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.1911226 , 0.63787633, 0.17100114]], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "24ebf2df",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Huy\\anaconda3\\lib\\site-packages\\sklearn\\base.py:310: UserWarning: Trying to unpickle estimator Ridge from version 0.22.2.post1 when using version 0.24.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'huy là ta'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = 'Huy là ta'\n",
    "preprocessing(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "725dbe77-d31c-4d38-8a91-9f14c0d28e93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mọi người nghe rõ không'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessing('mn nghe rõ không :)))')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1564e408",
   "metadata": {},
   "outputs": [],
   "source": [
    "da_path = os.path.abspath('../dictionary/abbreviation_dictionary_vn.xlsx')\n",
    "duplicate_abb = pd.read_excel(da_path,sheet_name='duplicate',header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fe1b0881-6cd1-4b09-9379-bde29721c898",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d30e8552-da9e-4101-9f49-3ed41a7164ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = len(sys.argv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0837010b-ad29-431d-b569-2e210ccfc2b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Name of Python script: C:\\Users\\Huy\\anaconda3\\envs\\Homura2\\lib\\site-packages\\ipykernel_launcher.py\n",
      "\n",
      "Arguments passed: -f C:\\Users\\Huy\\AppData\\Roaming\\jupyter\\runtime\\kernel-e800c74a-48fd-4744-9655-32cf5ed63009.json "
     ]
    }
   ],
   "source": [
    "# Arguments passed\n",
    "print(\"\\nName of Python script:\", sys.argv[0])\n",
    " \n",
    "print(\"\\nArguments passed:\", end = \" \")\n",
    "for i in range(1, n):\n",
    "    print(sys.argv[i], end = \" \")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
